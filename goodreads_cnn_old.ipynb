{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from utils import predicted_test_data_to_result_csv\n",
    "from keras import layers\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(os.environ['LD_LIBRARY_PATH'])\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "train_path = \"data/base/goodreads_train.csv\"\n",
    "test_path = \"data/base/goodreads_test.csv\"\n",
    "\n",
    "epochs = 10\n",
    "model_nb = 1\n",
    "\n",
    "max_features = 5000\n",
    "sequence_length = 100\n",
    "\n",
    "embedding_dim = 50\n",
    "learning_rate = 0.0001\n",
    "batch_size = 10000\n",
    "dropout_rate = 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df_train[(df_train['rating'] == 0)].index\n",
    "df_train.drop(index, inplace=True)\n",
    "df_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train.pop('rating')\n",
    "target = target - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train[\"review_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = tf.data.Dataset.from_tensor_slices((features, target)).shuffle(10, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def is_test(x, y):\n",
    "    return x % 4 == 0\n",
    "\n",
    "def is_train(x, y):\n",
    "    return not is_test(x, y)\n",
    "\n",
    "recover = lambda x,y: y\n",
    "\n",
    "raw_validation_dataset = all_data.enumerate() \\\n",
    "                    .filter(is_test) \\\n",
    "                    .map(recover)\n",
    "\n",
    "raw_train_dataset = all_data.enumerate() \\\n",
    "                    .filter(is_train) \\\n",
    "                    .map(recover)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "raw_train_dataset = raw_train_dataset.batch(batch_size=batch_size)\n",
    "raw_validation_dataset = raw_validation_dataset.batch(batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_spoilers = tf.strings.regex_replace(lowercase, '\\*\\* spoiler alert \\*\\*', ' ')\n",
    "    return tf.strings.regex_replace(stripped_spoilers,\n",
    "                                    '[%s]' % re.escape(string.punctuation),\n",
    "                                    '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_dataset.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)\n",
    "\n",
    "validation_text = raw_validation_dataset.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(validation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_dataset.map(vectorize_text)\n",
    "validation_ds = raw_validation_dataset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 50)           250050    \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 100, 64)           9664      \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 33, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 33, 128)           41088     \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 33, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 11, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 11, 256)           164096    \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 11, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 3, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 3, 512)            655872    \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 3, 512)            1311232   \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 1, 512)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 512)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,870,919\n",
      "Trainable params: 2,870,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(max_features + 1, embedding_dim, input_length=sequence_length))\n",
    "\n",
    "model.add(layers.Conv1D(64, 3, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(64, 3, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(3)) # 2 => 3\n",
    "# model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "model.add(layers.Conv1D(128, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(128, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "# model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "model.add(layers.Conv1D(256, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(256, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "# model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "model.add(layers.Conv1D(512, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(512, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "# model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "# model.add(layers.Dropout(dropout_rate))\n",
    "model.add(layers.Dense(5, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=keras.metrics.sparse_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "exp_name = f'conv_net_model_{model_nb}_lr_{learning_rate}_bs_{batch_size}_emb_{embedding_dim}_dr_{dropout_rate}'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 55s 829ms/step - loss: 1.3768 - sparse_categorical_accuracy: 0.3569 - val_loss: 1.2789 - val_sparse_categorical_accuracy: 0.3760\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 54s 812ms/step - loss: 1.2045 - sparse_categorical_accuracy: 0.4436 - val_loss: 1.1407 - val_sparse_categorical_accuracy: 0.4860\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 55s 838ms/step - loss: 1.1237 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.1023 - val_sparse_categorical_accuracy: 0.5045\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 53s 794ms/step - loss: 1.0840 - sparse_categorical_accuracy: 0.5141 - val_loss: 1.0781 - val_sparse_categorical_accuracy: 0.5130\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 51s 779ms/step - loss: 1.0291 - sparse_categorical_accuracy: 0.5370 - val_loss: 1.0286 - val_sparse_categorical_accuracy: 0.5344\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 52s 783ms/step - loss: 0.9925 - sparse_categorical_accuracy: 0.5536 - val_loss: 0.9986 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 52s 785ms/step - loss: 0.9700 - sparse_categorical_accuracy: 0.5642 - val_loss: 0.9884 - val_sparse_categorical_accuracy: 0.5570\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 51s 778ms/step - loss: 0.9518 - sparse_categorical_accuracy: 0.5734 - val_loss: 0.9844 - val_sparse_categorical_accuracy: 0.5601\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 53s 802ms/step - loss: 0.9400 - sparse_categorical_accuracy: 0.5790 - val_loss: 0.9736 - val_sparse_categorical_accuracy: 0.5653\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 53s 797ms/step - loss: 0.9269 - sparse_categorical_accuracy: 0.5855 - val_loss: 0.9711 - val_sparse_categorical_accuracy: 0.5669\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(\"logs/\" + exp_name)],\n",
    "    validation_data=validation_ds,\n",
    "    epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    model\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(), metrics=keras.metrics.sparse_categorical_accuracy\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_path, sep=\",\")\n",
    "\n",
    "df_test_modified = df_test.drop(columns=[\n",
    "    'user_id',\n",
    "    'book_id',\n",
    "    'review_id',\n",
    "    'date_added',\n",
    "    'date_updated',\n",
    "    'read_at',\n",
    "    'started_at',\n",
    "    'n_votes',\n",
    "    'n_comments'\n",
    "], inplace=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14939/14939 [==============================] - 69s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_data_numpy = df_test.to_numpy()\n",
    "\n",
    "predicted_test_data = export_model.predict(df_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  b9450d1c1f97f891c392b1105959b56e   7092507   \n1  b9450d1c1f97f891c392b1105959b56e   5576654   \n2  b9450d1c1f97f891c392b1105959b56e  15754052   \n3  b9450d1c1f97f891c392b1105959b56e     17020   \n4  b9450d1c1f97f891c392b1105959b56e  12551082   \n\n                          review_id  \\\n0  5c4df7e70e9b438c761f07a4620ccb7c   \n1  8eaeaf13213eeb16ad879a2a2591bbe5   \n2  dce649b733c153ba5363a0413cac988f   \n3  8a46df0bb997269d6834f9437a4b0a77   \n4  d11d3091e22f1cf3cb865598de197599   \n\n                                         review_text  \\\n0  ** spoiler alert ** \\n This is definitely one ...   \n1  ** spoiler alert ** \\n \"You are what you drink...   \n2  Roar is one of my favorite characters in Under...   \n3  ** spoiler alert ** \\n If you feel like travel...   \n4  3.5 stars \\n I read and enjoyed the first two ...   \n\n                       date_added                    date_updated  \\\n0  Sat Nov 10 06:06:13 -0800 2012  Sun Nov 11 05:38:36 -0800 2012   \n1  Fri Nov 09 21:55:16 -0800 2012  Sat Nov 10 05:41:49 -0800 2012   \n2  Fri Nov 09 00:25:50 -0800 2012  Sat Nov 10 06:14:10 -0800 2012   \n3  Thu Nov 01 00:28:39 -0700 2012  Sat Nov 03 11:35:22 -0700 2012   \n4  Thu Oct 18 00:57:00 -0700 2012  Mon Apr 01 23:00:51 -0700 2013   \n\n                          read_at                      started_at  n_votes  \\\n0  Sun Nov 11 05:38:36 -0800 2012  Sat Nov 10 00:00:00 -0800 2012        1   \n1  Sat Nov 10 05:41:49 -0800 2012  Fri Nov 09 00:00:00 -0800 2012        1   \n2  Sat Nov 10 06:14:10 -0800 2012  Fri Nov 09 00:00:00 -0800 2012        0   \n3  Sat Nov 03 11:35:22 -0700 2012  Thu Nov 01 00:00:00 -0700 2012        0   \n4  Sat Mar 30 00:00:00 -0700 2013  Fri Mar 29 00:00:00 -0700 2013        0   \n\n   n_comments  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>7092507</td>\n      <td>5c4df7e70e9b438c761f07a4620ccb7c</td>\n      <td>** spoiler alert ** \\n This is definitely one ...</td>\n      <td>Sat Nov 10 06:06:13 -0800 2012</td>\n      <td>Sun Nov 11 05:38:36 -0800 2012</td>\n      <td>Sun Nov 11 05:38:36 -0800 2012</td>\n      <td>Sat Nov 10 00:00:00 -0800 2012</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>5576654</td>\n      <td>8eaeaf13213eeb16ad879a2a2591bbe5</td>\n      <td>** spoiler alert ** \\n \"You are what you drink...</td>\n      <td>Fri Nov 09 21:55:16 -0800 2012</td>\n      <td>Sat Nov 10 05:41:49 -0800 2012</td>\n      <td>Sat Nov 10 05:41:49 -0800 2012</td>\n      <td>Fri Nov 09 00:00:00 -0800 2012</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>15754052</td>\n      <td>dce649b733c153ba5363a0413cac988f</td>\n      <td>Roar is one of my favorite characters in Under...</td>\n      <td>Fri Nov 09 00:25:50 -0800 2012</td>\n      <td>Sat Nov 10 06:14:10 -0800 2012</td>\n      <td>Sat Nov 10 06:14:10 -0800 2012</td>\n      <td>Fri Nov 09 00:00:00 -0800 2012</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>17020</td>\n      <td>8a46df0bb997269d6834f9437a4b0a77</td>\n      <td>** spoiler alert ** \\n If you feel like travel...</td>\n      <td>Thu Nov 01 00:28:39 -0700 2012</td>\n      <td>Sat Nov 03 11:35:22 -0700 2012</td>\n      <td>Sat Nov 03 11:35:22 -0700 2012</td>\n      <td>Thu Nov 01 00:00:00 -0700 2012</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>12551082</td>\n      <td>d11d3091e22f1cf3cb865598de197599</td>\n      <td>3.5 stars \\n I read and enjoyed the first two ...</td>\n      <td>Thu Oct 18 00:57:00 -0700 2012</td>\n      <td>Mon Apr 01 23:00:51 -0700 2013</td>\n      <td>Sat Mar 30 00:00:00 -0700 2013</td>\n      <td>Fri Mar 29 00:00:00 -0700 2013</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_data_to_result_csv(df_test, predicted_test_data, exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export_model.save(\"saved_model/embedding_model_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
