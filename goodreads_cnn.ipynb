{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from utils import predicted_test_data_to_result_csv\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(os.environ['LD_LIBRARY_PATH'])\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  8842281e1d1347389f2ab93d60773d4d  18245960   \n1  8842281e1d1347389f2ab93d60773d4d     16981   \n2  8842281e1d1347389f2ab93d60773d4d  28684704   \n3  8842281e1d1347389f2ab93d60773d4d  27161156   \n4  8842281e1d1347389f2ab93d60773d4d  25884323   \n\n                          review_id  rating  \\\n0  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n1  a5d2c3628987712d0e05c4f90798eb67       3   \n2  2ede853b14dc4583f96cf5d120af636f       3   \n3  ced5675e55cd9d38a524743f5c40996e       0   \n4  332732725863131279a8e345b63ac33e       4   \n\n                                         review_text  \\\n0  This is a special book. It started slow for ab...   \n1  Recommended by Don Katz. Avail for free in Dec...   \n2  A fun, fast paced science fiction thriller. I ...   \n3  Recommended reading to understand what is goin...   \n4  I really enjoyed this book, and there is a lot...   \n\n                       date_added                    date_updated  \\\n0  Sun Jul 30 07:44:10 -0700 2017  Wed Aug 30 00:00:26 -0700 2017   \n1  Mon Dec 05 10:46:44 -0800 2016  Wed Mar 22 11:37:04 -0700 2017   \n2  Tue Nov 15 11:29:22 -0800 2016  Mon Mar 20 23:40:27 -0700 2017   \n3  Wed Nov 09 17:37:04 -0800 2016  Wed Nov 09 17:38:20 -0800 2016   \n4  Mon Apr 25 09:31:23 -0700 2016  Mon Apr 25 09:31:23 -0700 2016   \n\n                          read_at                      started_at  n_votes  \\\n0  Sat Aug 26 12:05:52 -0700 2017  Tue Aug 15 13:23:18 -0700 2017       28   \n1                             NaN                             NaN        1   \n2  Sat Mar 18 23:22:42 -0700 2017  Fri Mar 17 23:45:40 -0700 2017       22   \n3                             NaN                             NaN        5   \n4  Sun Jun 26 00:00:00 -0700 2016  Sat May 28 00:00:00 -0700 2016        9   \n\n   n_comments  \n0           1  \n1           0  \n2           0  \n3           1  \n4           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>18245960</td>\n      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n      <td>5</td>\n      <td>This is a special book. It started slow for ab...</td>\n      <td>Sun Jul 30 07:44:10 -0700 2017</td>\n      <td>Wed Aug 30 00:00:26 -0700 2017</td>\n      <td>Sat Aug 26 12:05:52 -0700 2017</td>\n      <td>Tue Aug 15 13:23:18 -0700 2017</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>16981</td>\n      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n      <td>3</td>\n      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n      <td>Mon Dec 05 10:46:44 -0800 2016</td>\n      <td>Wed Mar 22 11:37:04 -0700 2017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>28684704</td>\n      <td>2ede853b14dc4583f96cf5d120af636f</td>\n      <td>3</td>\n      <td>A fun, fast paced science fiction thriller. I ...</td>\n      <td>Tue Nov 15 11:29:22 -0800 2016</td>\n      <td>Mon Mar 20 23:40:27 -0700 2017</td>\n      <td>Sat Mar 18 23:22:42 -0700 2017</td>\n      <td>Fri Mar 17 23:45:40 -0700 2017</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>27161156</td>\n      <td>ced5675e55cd9d38a524743f5c40996e</td>\n      <td>0</td>\n      <td>Recommended reading to understand what is goin...</td>\n      <td>Wed Nov 09 17:37:04 -0800 2016</td>\n      <td>Wed Nov 09 17:38:20 -0800 2016</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>25884323</td>\n      <td>332732725863131279a8e345b63ac33e</td>\n      <td>4</td>\n      <td>I really enjoyed this book, and there is a lot...</td>\n      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n      <td>Sun Jun 26 00:00:00 -0700 2016</td>\n      <td>Sat May 28 00:00:00 -0700 2016</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/base/goodreads_train.csv\", sep=\",\")\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  8842281e1d1347389f2ab93d60773d4d  18245960   \n1  8842281e1d1347389f2ab93d60773d4d     16981   \n2  8842281e1d1347389f2ab93d60773d4d  28684704   \n3  8842281e1d1347389f2ab93d60773d4d  25884323   \n4  8842281e1d1347389f2ab93d60773d4d  19398490   \n\n                          review_id  rating  \\\n0  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n1  a5d2c3628987712d0e05c4f90798eb67       3   \n2  2ede853b14dc4583f96cf5d120af636f       3   \n3  332732725863131279a8e345b63ac33e       4   \n4  ea4a220b10e6b5c796dae0e3b970aff1       4   \n\n                                         review_text  \\\n0  This is a special book. It started slow for ab...   \n1  Recommended by Don Katz. Avail for free in Dec...   \n2  A fun, fast paced science fiction thriller. I ...   \n3  I really enjoyed this book, and there is a lot...   \n4  A beautiful story. It is rare to encounter a b...   \n\n                       date_added                    date_updated  \\\n0  Sun Jul 30 07:44:10 -0700 2017  Wed Aug 30 00:00:26 -0700 2017   \n1  Mon Dec 05 10:46:44 -0800 2016  Wed Mar 22 11:37:04 -0700 2017   \n2  Tue Nov 15 11:29:22 -0800 2016  Mon Mar 20 23:40:27 -0700 2017   \n3  Mon Apr 25 09:31:23 -0700 2016  Mon Apr 25 09:31:23 -0700 2016   \n4  Sun Jan 03 21:20:46 -0800 2016  Tue Sep 20 23:30:15 -0700 2016   \n\n                          read_at                      started_at  n_votes  \\\n0  Sat Aug 26 12:05:52 -0700 2017  Tue Aug 15 13:23:18 -0700 2017       28   \n1                             NaN                             NaN        1   \n2  Sat Mar 18 23:22:42 -0700 2017  Fri Mar 17 23:45:40 -0700 2017       22   \n3  Sun Jun 26 00:00:00 -0700 2016  Sat May 28 00:00:00 -0700 2016        9   \n4  Tue Sep 13 11:51:51 -0700 2016  Sat Aug 20 07:03:03 -0700 2016       35   \n\n   n_comments  \n0           1  \n1           0  \n2           0  \n3           1  \n4           5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>18245960</td>\n      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n      <td>5</td>\n      <td>This is a special book. It started slow for ab...</td>\n      <td>Sun Jul 30 07:44:10 -0700 2017</td>\n      <td>Wed Aug 30 00:00:26 -0700 2017</td>\n      <td>Sat Aug 26 12:05:52 -0700 2017</td>\n      <td>Tue Aug 15 13:23:18 -0700 2017</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>16981</td>\n      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n      <td>3</td>\n      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n      <td>Mon Dec 05 10:46:44 -0800 2016</td>\n      <td>Wed Mar 22 11:37:04 -0700 2017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>28684704</td>\n      <td>2ede853b14dc4583f96cf5d120af636f</td>\n      <td>3</td>\n      <td>A fun, fast paced science fiction thriller. I ...</td>\n      <td>Tue Nov 15 11:29:22 -0800 2016</td>\n      <td>Mon Mar 20 23:40:27 -0700 2017</td>\n      <td>Sat Mar 18 23:22:42 -0700 2017</td>\n      <td>Fri Mar 17 23:45:40 -0700 2017</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>25884323</td>\n      <td>332732725863131279a8e345b63ac33e</td>\n      <td>4</td>\n      <td>I really enjoyed this book, and there is a lot...</td>\n      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n      <td>Sun Jun 26 00:00:00 -0700 2016</td>\n      <td>Sat May 28 00:00:00 -0700 2016</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>19398490</td>\n      <td>ea4a220b10e6b5c796dae0e3b970aff1</td>\n      <td>4</td>\n      <td>A beautiful story. It is rare to encounter a b...</td>\n      <td>Sun Jan 03 21:20:46 -0800 2016</td>\n      <td>Tue Sep 20 23:30:15 -0700 2016</td>\n      <td>Tue Sep 13 11:51:51 -0700 2016</td>\n      <td>Sat Aug 20 07:03:03 -0700 2016</td>\n      <td>35</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df_train[(df_train['rating'] == 0)].index\n",
    "df_train.drop(index, inplace=True)\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0    4\n1    2\n2    2\n3    3\n4    3\nName: rating, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df_train.pop('rating')\n",
    "\n",
    "target = target - 1\n",
    "\n",
    "target.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0    This is a special book. It started slow for ab...\n1    Recommended by Don Katz. Avail for free in Dec...\n2    A fun, fast paced science fiction thriller. I ...\n3    I really enjoyed this book, and there is a lot...\n4    A beautiful story. It is rare to encounter a b...\nName: review_text, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_train[\"review_text\"]\n",
    "\n",
    "features.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "raw_train_ds = tf.data.Dataset.from_tensor_slices((features, target))\n",
    "raw_train_ds = raw_train_ds.batch(32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_spoilers = tf.strings.regex_replace(lowercase, '\\*\\* spoiler alert \\*\\*', ' ')\n",
    "    return tf.strings.regex_replace(stripped_spoilers,\n",
    "                                    '[%s]' % re.escape(string.punctuation),\n",
    "                                    '')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<MapDataset element_spec=(TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "embedding_dim = 200"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           500050    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 64)           9664      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 64)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 50, 128)           41088     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 50, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 16, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 16, 256)           164096    \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 16, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 5, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 256)            0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,145,623\n",
      "Trainable params: 1,145,623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(max_features + 1, 50, input_length=sequence_length))\n",
    "\n",
    "model.add(layers.Conv1D(64, 3, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(64, 3, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(128, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(128, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(256, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.Conv1D(256, 5, activation = 'relu', padding = 'same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(5, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2586/27157 [=>............................] - ETA: 29:44 - loss: 1.3859 - accuracy: 0.3608"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    model,\n",
    "    layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/base/goodreads_test.csv\", sep=\",\")\n",
    "\n",
    "df_test_modified = df_test.drop(columns=[\n",
    "    'user_id',\n",
    "    'book_id',\n",
    "    'review_id',\n",
    "    'date_added',\n",
    "    'date_updated',\n",
    "    'read_at',\n",
    "    'started_at',\n",
    "    'n_votes',\n",
    "    'n_comments'\n",
    "], inplace=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_data_numpy = df_test.to_numpy()\n",
    "\n",
    "predicted_test_data = export_model.predict(df_test_modified)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_test_data_to_result_csv(df_test, predicted_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "export_model.save(\"saved_model/embedding_model_1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
