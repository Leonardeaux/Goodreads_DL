{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"data/base/goodreads_train.csv\"\n",
    "result_path = \"data/base/goodreads_test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "\n",
    "df_train.drop(columns=['user_id', 'book_id', 'date_added', 'date_updated',\n",
    "                            'read_at', 'started_at', 'n_votes', 'n_comments'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\enzol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_review(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    text = re.sub(r'(view spoiler|hide spoiler)', '', text)\n",
    "\n",
    "    tokens = text.split()\n",
    "\n",
    "    clean_tokens = [WordNetLemmatizer().lemmatize(tok) for tok in tokens if\n",
    "                     tok not in stopwords_english and len(tok) > 1]\n",
    "    # # clean_tokens = [tok for tok in tokens if tok not in stopwords_english and len(tok) > 1]\n",
    "\n",
    "    clean_text = ' '.join(clean_tokens)\n",
    "\n",
    "    return clean_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "df_train[\"clean_text\"] = df_train[\"review_text\"].apply(preprocess_review)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (720000,) (720000,)\n",
      "Validation data: (180000,) (180000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train = df_train[\"clean_text\"].values\n",
    "y_train = df_train[\"rating\"].values\n",
    "\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training data:\", x_tr.shape, y_tr.shape)\n",
    "print(\"Validation data:\", x_va.shape, y_va.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "caracteres = \"abcdefghijklmnopqrstuvwxyz \"\n",
    "\n",
    "VOCAB_SIZE = 30\n",
    "MAX_SEQ_LENGTH = 250\n",
    "EMBEDDING_DIMS = 128"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, char_level=True, filters=caracteres)\n",
    "tokenizer.fit_on_texts(x_tr)\n",
    "\n",
    "x_tr_seq = tokenizer.texts_to_sequences(x_tr)\n",
    "x_tr_seq = pad_sequences(x_tr_seq, maxlen=MAX_SEQ_LENGTH)\n",
    "\n",
    "x_va_seq = tokenizer.texts_to_sequences(x_va)\n",
    "x_va_seq = pad_sequences(x_va_seq, maxlen=MAX_SEQ_LENGTH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "'e review'"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "(720000,)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  2,  1,  8,  2, 23,  5,  2, 21])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_seq[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "(720000, 250)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_seq.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "model_nb = 2\n",
    "hidden_layer = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1024\n",
    "dropout_rate = 0.4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 250)]             0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 250, 128)          3840      \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 250, 128)         98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 250, 128)         98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 256)              263168    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 473,062\n",
      "Trainable params: 473,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, BatchNormalization, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_text = Input(shape=(MAX_SEQ_LENGTH,))\n",
    "\n",
    "embedding_layer = Embedding(VOCAB_SIZE, output_dim=EMBEDDING_DIMS, input_length=MAX_SEQ_LENGTH)(input_text)\n",
    "\n",
    "x = embedding_layer\n",
    "\n",
    "for _ in range(hidden_layer):\n",
    "    x = Bidirectional(LSTM(units=int(EMBEDDING_DIMS//2), dropout=dropout_rate, return_sequences=True))(x)\n",
    "\n",
    "last = Bidirectional(LSTM(units=EMBEDDING_DIMS, dropout=dropout_rate))(x)\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "dense = Dense(units=32, activation='relu')(last)\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "output = Dense(units=6, activation='softmax')(dense)\n",
    "\n",
    "rnn_model = Model(input_text, output)\n",
    "\n",
    "rnn_model.summary()\n",
    "\n",
    "rnn_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "earlystopping_cb = EarlyStopping(patience=6, restore_best_weights=True)\n",
    "tensorboard = TensorBoard(f\"logs/char/rnn_model_{model_nb}_hidden_layers_{hidden_layer}_lr_{learning_rate}_bs_{batch_size}_dr_{dropout_rate}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - 165s 227ms/step - loss: 1.4554 - accuracy: 0.3645 - val_loss: 1.4415 - val_accuracy: 0.3724\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 158s 225ms/step - loss: 1.4169 - accuracy: 0.3878 - val_loss: 1.3967 - val_accuracy: 0.3961\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.3926 - accuracy: 0.4013 - val_loss: 1.3677 - val_accuracy: 0.4140\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.3546 - accuracy: 0.4175 - val_loss: 1.3304 - val_accuracy: 0.4253\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.3163 - accuracy: 0.4331 - val_loss: 1.2873 - val_accuracy: 0.4432\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 158s 224ms/step - loss: 1.2818 - accuracy: 0.4477 - val_loss: 1.2527 - val_accuracy: 0.4582\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 1.2545 - accuracy: 0.4589 - val_loss: 1.2276 - val_accuracy: 0.4705\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 154s 218ms/step - loss: 1.2319 - accuracy: 0.4693 - val_loss: 1.2098 - val_accuracy: 0.4752\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 1.2131 - accuracy: 0.4769 - val_loss: 1.1909 - val_accuracy: 0.4862\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 155s 221ms/step - loss: 1.1964 - accuracy: 0.4845 - val_loss: 1.1770 - val_accuracy: 0.4911\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 154s 219ms/step - loss: 1.1826 - accuracy: 0.4906 - val_loss: 1.1631 - val_accuracy: 0.4987\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 155s 221ms/step - loss: 1.1712 - accuracy: 0.4952 - val_loss: 1.1650 - val_accuracy: 0.4979\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.1613 - accuracy: 0.5000 - val_loss: 1.1495 - val_accuracy: 0.5058\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 156s 221ms/step - loss: 1.1531 - accuracy: 0.5036 - val_loss: 1.1423 - val_accuracy: 0.5069\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 161s 228ms/step - loss: 1.1453 - accuracy: 0.5069 - val_loss: 1.1467 - val_accuracy: 0.5075\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 156s 221ms/step - loss: 1.1386 - accuracy: 0.5101 - val_loss: 1.1385 - val_accuracy: 0.5096\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 163s 232ms/step - loss: 1.1322 - accuracy: 0.5124 - val_loss: 1.1311 - val_accuracy: 0.5138\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 162s 230ms/step - loss: 1.1274 - accuracy: 0.5149 - val_loss: 1.1294 - val_accuracy: 0.5147\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 157s 223ms/step - loss: 1.1216 - accuracy: 0.5170 - val_loss: 1.1275 - val_accuracy: 0.5171\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.1176 - accuracy: 0.5187 - val_loss: 1.1234 - val_accuracy: 0.5170\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.1125 - accuracy: 0.5210 - val_loss: 1.1205 - val_accuracy: 0.5188\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 1.1085 - accuracy: 0.5225 - val_loss: 1.1230 - val_accuracy: 0.5185\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 151s 214ms/step - loss: 1.1051 - accuracy: 0.5247 - val_loss: 1.1217 - val_accuracy: 0.5193\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.1020 - accuracy: 0.5261 - val_loss: 1.1208 - val_accuracy: 0.5190\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0977 - accuracy: 0.5276 - val_loss: 1.1173 - val_accuracy: 0.5217\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 151s 214ms/step - loss: 1.0951 - accuracy: 0.5290 - val_loss: 1.1191 - val_accuracy: 0.5201\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 153s 217ms/step - loss: 1.0920 - accuracy: 0.5298 - val_loss: 1.1348 - val_accuracy: 0.5150\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.0887 - accuracy: 0.5317 - val_loss: 1.1186 - val_accuracy: 0.5212\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.0859 - accuracy: 0.5326 - val_loss: 1.1156 - val_accuracy: 0.5228\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0838 - accuracy: 0.5343 - val_loss: 1.1143 - val_accuracy: 0.5226\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 149s 211ms/step - loss: 1.0808 - accuracy: 0.5350 - val_loss: 1.1212 - val_accuracy: 0.5215\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 150s 213ms/step - loss: 1.0790 - accuracy: 0.5361 - val_loss: 1.1174 - val_accuracy: 0.5231\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 153s 217ms/step - loss: 1.0766 - accuracy: 0.5368 - val_loss: 1.1242 - val_accuracy: 0.5191\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0742 - accuracy: 0.5379 - val_loss: 1.1173 - val_accuracy: 0.5228\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0716 - accuracy: 0.5392 - val_loss: 1.1229 - val_accuracy: 0.5234\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 153s 218ms/step - loss: 1.0705 - accuracy: 0.5400 - val_loss: 1.1213 - val_accuracy: 0.5216\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.0677 - accuracy: 0.5413 - val_loss: 1.1235 - val_accuracy: 0.5226\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0662 - accuracy: 0.5414 - val_loss: 1.1170 - val_accuracy: 0.5223\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0637 - accuracy: 0.5425 - val_loss: 1.1230 - val_accuracy: 0.5222\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.0621 - accuracy: 0.5433 - val_loss: 1.1281 - val_accuracy: 0.5213\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.0603 - accuracy: 0.5441 - val_loss: 1.1199 - val_accuracy: 0.5240\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.0588 - accuracy: 0.5451 - val_loss: 1.1202 - val_accuracy: 0.5222\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 153s 217ms/step - loss: 1.0565 - accuracy: 0.5459 - val_loss: 1.1189 - val_accuracy: 0.5224\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 151s 215ms/step - loss: 1.0558 - accuracy: 0.5469 - val_loss: 1.1207 - val_accuracy: 0.5228\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 153s 217ms/step - loss: 1.0540 - accuracy: 0.5463 - val_loss: 1.1365 - val_accuracy: 0.5172\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 163s 232ms/step - loss: 1.0523 - accuracy: 0.5480 - val_loss: 1.1254 - val_accuracy: 0.5212\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 163s 232ms/step - loss: 1.0508 - accuracy: 0.5485 - val_loss: 1.1253 - val_accuracy: 0.5241\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 179s 255ms/step - loss: 1.0494 - accuracy: 0.5488 - val_loss: 1.1228 - val_accuracy: 0.5210\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 159s 226ms/step - loss: 1.0486 - accuracy: 0.5492 - val_loss: 1.1294 - val_accuracy: 0.5221\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 1.0463 - accuracy: 0.5503 - val_loss: 1.1249 - val_accuracy: 0.5225\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 157s 224ms/step - loss: 1.0447 - accuracy: 0.5504 - val_loss: 1.1247 - val_accuracy: 0.5235\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 157s 223ms/step - loss: 1.0432 - accuracy: 0.5517 - val_loss: 1.1281 - val_accuracy: 0.5212\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 1.0423 - accuracy: 0.5519 - val_loss: 1.1281 - val_accuracy: 0.5219\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 1.0404 - accuracy: 0.5529 - val_loss: 1.1280 - val_accuracy: 0.5226\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 157s 223ms/step - loss: 1.0398 - accuracy: 0.5530 - val_loss: 1.1346 - val_accuracy: 0.5214\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 1.0380 - accuracy: 0.5541 - val_loss: 1.1423 - val_accuracy: 0.5185\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 1.0374 - accuracy: 0.5537 - val_loss: 1.1311 - val_accuracy: 0.5213\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 153s 218ms/step - loss: 1.0365 - accuracy: 0.5546 - val_loss: 1.1292 - val_accuracy: 0.5213\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 154s 218ms/step - loss: 1.0343 - accuracy: 0.5556 - val_loss: 1.1331 - val_accuracy: 0.5211\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 153s 217ms/step - loss: 1.0340 - accuracy: 0.5556 - val_loss: 1.1389 - val_accuracy: 0.5221\n",
      "Epoch 61/100\n",
      "231/704 [========>.....................] - ETA: 1:33 - loss: 1.0296 - accuracy: 0.5576"
     ]
    }
   ],
   "source": [
    "rnn_model.fit(x_tr_seq,\n",
    "                    y_tr,\n",
    "                    validation_data=(x_va_seq, y_va),\n",
    "                    callbacks=[tensorboard],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(result_path, sep=\",\")\n",
    "\n",
    "df_test.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['user_id', 'book_id', 'date_added', 'date_updated',\n",
    "                                'read_at', 'started_at', 'n_votes', 'n_comments'])\n",
    "\n",
    "df_test[\"clean_text\"] = df_test[\"review_text\"].apply(preprocess_review)\n",
    "\n",
    "df_test = df_test.drop(columns=['review_text'])\n",
    "\n",
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_te = df_test[\"clean_text\"].values\n",
    "\n",
    "x_te_seq = tokenizer.texts_to_sequences(x_te)\n",
    "x_te_seq = pad_sequences(x_te_seq, maxlen=MAX_SEQ_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = [np.argmax(i) for i in rnn_model.predict(x_te_seq)]\n",
    "\n",
    "# Create a new DataFrame to merge review ids and the model predictions\n",
    "submission = pd.DataFrame({'review_id': df_test.review_id, 'rating': predictions})\n",
    "\n",
    "# Check few random entries\n",
    "submission.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission.to_csv(\"res_files/submission.csv\", index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = rnn_model.evaluate(x_va_seq,y_va)\n",
    "\n",
    "print('Validation loss:', test_loss)\n",
    "print('Validation accuracy:', test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
