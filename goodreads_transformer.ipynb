{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from utils import predicted_test_data_to_result_csv\n",
    "from keras import layers, losses, Input, Model\n",
    "from keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, BatchNormalization, Activation, \\\n",
    "    Flatten, LSTM, SpatialDropout1D, Bidirectional, MultiHeadAttention, LayerNormalization, Lambda, \\\n",
    "    GlobalAveragePooling1D, Dropout\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.metrics import sparse_categorical_accuracy\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_path = \"data/base/goodreads_train.csv\"\n",
    "result_path = \"data/base/goodreads_test.csv\"\n",
    "frac_ratio = 0.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "max_features = 10000  # Maximum vocab size.\n",
    "sequence_length = 200"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "index = df[(df['rating'] == 0)].index\n",
    "df.drop(index, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "x_train = df.sample(frac=frac_ratio)\n",
    "x_val = df.drop(x_train.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "y_train = x_train.pop('rating')\n",
    "y_train = y_train - 1\n",
    "\n",
    "y_val = x_val.pop('rating')\n",
    "y_val = y_val - 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_train = x_train[\"review_text\"]\n",
    "x_val = x_val[\"review_text\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "raw_train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10, reshuffle_each_iteration=False)\n",
    "raw_val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(10, reshuffle_each_iteration=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\enzol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "# stopwords = stopwords.extend(['d', 'll', 're', 's', 've'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_spoilers = tf.strings.regex_replace(lowercase, '\\*\\* spoiler alert \\*\\*', ' ')\n",
    "    stripped_ponctuation = tf.strings.regex_replace(stripped_spoilers, \"[%s]\" % re.escape(string.punctuation), \"\")\n",
    "    data = []\n",
    "    for i in stopwords:\n",
    "        data = tf.strings.regex_replace(stripped_ponctuation, f' {i} ', \" \")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    pad_to_max_tokens=True,\n",
    "    output_sequence_length=sequence_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "model_nb = 1\n",
    "\n",
    "embedding_dim = 32 # Embedding size for each token\n",
    "num_heads = 4 # Number of attention heads\n",
    "ff_dim = 64  # Hidden layer size in feed forward network inside transformer\n",
    "learning_rate = 0.007\n",
    "batch_size = 1024\n",
    "dropout_rate = 0.3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "raw_train_dataset = raw_train_dataset.batch(batch_size=batch_size)\n",
    "raw_val_dataset = raw_val_dataset.batch(batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_dataset.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)\n",
    "\n",
    "val_text = raw_val_dataset.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(val_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train_ds = raw_train_dataset.map(vectorize_text)\n",
    "val_ds = raw_val_dataset.map(vectorize_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "input_text = Input(shape=(sequence_length,))\n",
    "\n",
    "embedding_layer = Embedding(max_features + 1, embedding_dim, input_length=sequence_length)(input_text)\n",
    "\n",
    "x = embedding_layer\n",
    "for _ in range(6):\n",
    "    old = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(num_heads, embedding_dim)(x, x)\n",
    "    x = x + old\n",
    "    old = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dense(embedding_dim * 2, activation=\"relu\")(x)\n",
    "    x = Dense(embedding_dim, activation=\"relu\")(x)\n",
    "    x = x + old\n",
    "\n",
    "mlp_head_input = Lambda(lambda x: x[:, 0])(x)\n",
    "\n",
    "dense = Dense(512, activation='relu')(mlp_head_input)\n",
    "\n",
    "output = Dense(5, activation='softmax')(dense)\n",
    "\n",
    "transformer_model = Model(input_text, output)\n",
    "\n",
    "transformer_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, ff_dim, rate=0):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation='relu'),\n",
    "             Dense(embedding_dim), ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embedding_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "\n",
    "        return x + positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen=sequence_length, vocab_size=max_features, embedding_dim=embedding_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embedding_dim=embedding_dim, num_heads=num_heads, ff_dim=ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "transformer_model = Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "transformer_model.compile(loss=sparse_categorical_crossentropy,\n",
    "                          optimizer=Adam(learning_rate=learning_rate),\n",
    "                          metrics=sparse_categorical_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "exp_name = f'transformer_model_with_stopwords_{model_nb}_num_heads_{num_heads}_emb_dim_{embedding_dim}_ff_dim_{ff_dim}_lr_{learning_rate}_bs_{batch_size}_dr_{dropout_rate}'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer TokenAndPositionEmbedding has arguments ['maxlen', 'vocab_size', 'embedding_dim']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/100\n",
      "170/170 [==============================] - 45s 256ms/step - loss: 1.3220 - sparse_categorical_accuracy: 0.3879 - val_loss: 1.0415 - val_sparse_categorical_accuracy: 0.5335\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 1.0280 - sparse_categorical_accuracy: 0.5382 - val_loss: 1.0260 - val_sparse_categorical_accuracy: 0.5378\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.9909 - sparse_categorical_accuracy: 0.5546 - val_loss: 1.0383 - val_sparse_categorical_accuracy: 0.5330\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 27s 161ms/step - loss: 0.9717 - sparse_categorical_accuracy: 0.5621 - val_loss: 1.0302 - val_sparse_categorical_accuracy: 0.5408\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.9563 - sparse_categorical_accuracy: 0.5669 - val_loss: 1.0462 - val_sparse_categorical_accuracy: 0.5390\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 27s 162ms/step - loss: 0.9419 - sparse_categorical_accuracy: 0.5735 - val_loss: 1.0658 - val_sparse_categorical_accuracy: 0.5367\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.9345 - sparse_categorical_accuracy: 0.5774 - val_loss: 1.0764 - val_sparse_categorical_accuracy: 0.5379\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 28s 164ms/step - loss: 0.9188 - sparse_categorical_accuracy: 0.5856 - val_loss: 1.1235 - val_sparse_categorical_accuracy: 0.5339\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 28s 165ms/step - loss: 0.9014 - sparse_categorical_accuracy: 0.5927 - val_loss: 1.1660 - val_sparse_categorical_accuracy: 0.5251\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 28s 163ms/step - loss: 0.8952 - sparse_categorical_accuracy: 0.5964 - val_loss: 1.2360 - val_sparse_categorical_accuracy: 0.5173\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 28s 163ms/step - loss: 0.8915 - sparse_categorical_accuracy: 0.5997 - val_loss: 1.1621 - val_sparse_categorical_accuracy: 0.5249\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 27s 159ms/step - loss: 0.8775 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.1761 - val_sparse_categorical_accuracy: 0.5238\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.8665 - sparse_categorical_accuracy: 0.6117 - val_loss: 1.1990 - val_sparse_categorical_accuracy: 0.5196\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.8568 - sparse_categorical_accuracy: 0.6158 - val_loss: 1.1796 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 27s 159ms/step - loss: 0.8489 - sparse_categorical_accuracy: 0.6186 - val_loss: 1.2413 - val_sparse_categorical_accuracy: 0.5028\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.8357 - sparse_categorical_accuracy: 0.6224 - val_loss: 1.2899 - val_sparse_categorical_accuracy: 0.5112\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 27s 159ms/step - loss: 0.8301 - sparse_categorical_accuracy: 0.6254 - val_loss: 1.3021 - val_sparse_categorical_accuracy: 0.5142\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 28s 163ms/step - loss: 0.8166 - sparse_categorical_accuracy: 0.6314 - val_loss: 1.2910 - val_sparse_categorical_accuracy: 0.5175\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 28s 164ms/step - loss: 0.8005 - sparse_categorical_accuracy: 0.6393 - val_loss: 1.3274 - val_sparse_categorical_accuracy: 0.5175\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 28s 162ms/step - loss: 0.7890 - sparse_categorical_accuracy: 0.6440 - val_loss: 1.4479 - val_sparse_categorical_accuracy: 0.5176\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 27s 161ms/step - loss: 0.7890 - sparse_categorical_accuracy: 0.6436 - val_loss: 1.3818 - val_sparse_categorical_accuracy: 0.5091\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.7876 - sparse_categorical_accuracy: 0.6463 - val_loss: 1.4499 - val_sparse_categorical_accuracy: 0.4960\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 27s 161ms/step - loss: 0.7796 - sparse_categorical_accuracy: 0.6491 - val_loss: 1.5193 - val_sparse_categorical_accuracy: 0.4977\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 27s 161ms/step - loss: 0.7700 - sparse_categorical_accuracy: 0.6529 - val_loss: 1.4472 - val_sparse_categorical_accuracy: 0.4995\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 28s 164ms/step - loss: 0.7568 - sparse_categorical_accuracy: 0.6589 - val_loss: 1.4071 - val_sparse_categorical_accuracy: 0.4987\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 27s 162ms/step - loss: 0.7358 - sparse_categorical_accuracy: 0.6676 - val_loss: 1.4564 - val_sparse_categorical_accuracy: 0.5004\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.7324 - sparse_categorical_accuracy: 0.6701 - val_loss: 1.4035 - val_sparse_categorical_accuracy: 0.4994\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 28s 167ms/step - loss: 0.7318 - sparse_categorical_accuracy: 0.6722 - val_loss: 1.4052 - val_sparse_categorical_accuracy: 0.4895\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 27s 161ms/step - loss: 0.7319 - sparse_categorical_accuracy: 0.6714 - val_loss: 1.4270 - val_sparse_categorical_accuracy: 0.4738\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 27s 162ms/step - loss: 0.7403 - sparse_categorical_accuracy: 0.6691 - val_loss: 1.3771 - val_sparse_categorical_accuracy: 0.4862\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 27s 161ms/step - loss: 0.7398 - sparse_categorical_accuracy: 0.6704 - val_loss: 1.4139 - val_sparse_categorical_accuracy: 0.4846\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 27s 160ms/step - loss: 0.7176 - sparse_categorical_accuracy: 0.6802 - val_loss: 1.5315 - val_sparse_categorical_accuracy: 0.4701\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.7131 - sparse_categorical_accuracy: 0.6814 - val_loss: 1.4169 - val_sparse_categorical_accuracy: 0.4831\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.7069 - sparse_categorical_accuracy: 0.6856 - val_loss: 1.4339 - val_sparse_categorical_accuracy: 0.5032\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6940 - sparse_categorical_accuracy: 0.6902 - val_loss: 1.5392 - val_sparse_categorical_accuracy: 0.5043\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.6958 - val_loss: 1.6544 - val_sparse_categorical_accuracy: 0.5007\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6768 - sparse_categorical_accuracy: 0.6987 - val_loss: 1.7827 - val_sparse_categorical_accuracy: 0.4922\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6758 - sparse_categorical_accuracy: 0.6986 - val_loss: 1.8881 - val_sparse_categorical_accuracy: 0.4988\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6593 - sparse_categorical_accuracy: 0.7079 - val_loss: 1.8836 - val_sparse_categorical_accuracy: 0.5008\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.7151 - val_loss: 1.8740 - val_sparse_categorical_accuracy: 0.5003\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6388 - sparse_categorical_accuracy: 0.7147 - val_loss: 1.8815 - val_sparse_categorical_accuracy: 0.4978\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6369 - sparse_categorical_accuracy: 0.7166 - val_loss: 1.8241 - val_sparse_categorical_accuracy: 0.4995\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 27s 158ms/step - loss: 0.6319 - sparse_categorical_accuracy: 0.7181 - val_loss: 1.7738 - val_sparse_categorical_accuracy: 0.4980\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 29s 170ms/step - loss: 0.6144 - sparse_categorical_accuracy: 0.7272 - val_loss: 1.8884 - val_sparse_categorical_accuracy: 0.4958\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.6078 - sparse_categorical_accuracy: 0.7311 - val_loss: 1.9839 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.7360 - val_loss: 1.9869 - val_sparse_categorical_accuracy: 0.4926\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 28s 167ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.7354 - val_loss: 1.9521 - val_sparse_categorical_accuracy: 0.4951\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.6011 - sparse_categorical_accuracy: 0.7345 - val_loss: 1.8800 - val_sparse_categorical_accuracy: 0.4879\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.6087 - sparse_categorical_accuracy: 0.7306 - val_loss: 1.8274 - val_sparse_categorical_accuracy: 0.4867\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 29s 170ms/step - loss: 0.6203 - sparse_categorical_accuracy: 0.7251 - val_loss: 1.8247 - val_sparse_categorical_accuracy: 0.4822\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 29s 170ms/step - loss: 0.6014 - sparse_categorical_accuracy: 0.7333 - val_loss: 1.9712 - val_sparse_categorical_accuracy: 0.4783\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.5856 - sparse_categorical_accuracy: 0.7414 - val_loss: 2.0473 - val_sparse_categorical_accuracy: 0.4781\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 29s 168ms/step - loss: 0.5749 - sparse_categorical_accuracy: 0.7459 - val_loss: 2.1108 - val_sparse_categorical_accuracy: 0.4893\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.5695 - sparse_categorical_accuracy: 0.7490 - val_loss: 2.2765 - val_sparse_categorical_accuracy: 0.4929\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 29s 170ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7527 - val_loss: 2.3563 - val_sparse_categorical_accuracy: 0.4952\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.7520 - val_loss: 2.1510 - val_sparse_categorical_accuracy: 0.4944\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.7575 - val_loss: 2.1819 - val_sparse_categorical_accuracy: 0.4899\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 29s 172ms/step - loss: 0.5384 - sparse_categorical_accuracy: 0.7618 - val_loss: 2.4164 - val_sparse_categorical_accuracy: 0.4915\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 28s 168ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.7651 - val_loss: 2.4765 - val_sparse_categorical_accuracy: 0.4869\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 28s 168ms/step - loss: 0.5270 - sparse_categorical_accuracy: 0.7667 - val_loss: 2.6076 - val_sparse_categorical_accuracy: 0.4814\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.5331 - sparse_categorical_accuracy: 0.7656 - val_loss: 2.6045 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 28s 167ms/step - loss: 0.5409 - sparse_categorical_accuracy: 0.7628 - val_loss: 2.4701 - val_sparse_categorical_accuracy: 0.4659\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.7593 - val_loss: 2.4522 - val_sparse_categorical_accuracy: 0.4807\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.5264 - sparse_categorical_accuracy: 0.7693 - val_loss: 2.5920 - val_sparse_categorical_accuracy: 0.4897\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.4969 - sparse_categorical_accuracy: 0.7812 - val_loss: 2.7372 - val_sparse_categorical_accuracy: 0.4895\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 28s 167ms/step - loss: 0.4851 - sparse_categorical_accuracy: 0.7860 - val_loss: 2.7518 - val_sparse_categorical_accuracy: 0.4866\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.4913 - sparse_categorical_accuracy: 0.7851 - val_loss: 2.7431 - val_sparse_categorical_accuracy: 0.4880\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 28s 166ms/step - loss: 0.4912 - sparse_categorical_accuracy: 0.7847 - val_loss: 2.5787 - val_sparse_categorical_accuracy: 0.4811\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.4937 - sparse_categorical_accuracy: 0.7854 - val_loss: 2.3891 - val_sparse_categorical_accuracy: 0.4719\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.4800 - sparse_categorical_accuracy: 0.7894 - val_loss: 2.5217 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 29s 172ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.7986 - val_loss: 2.6501 - val_sparse_categorical_accuracy: 0.4756\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 29s 168ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.8023 - val_loss: 2.7004 - val_sparse_categorical_accuracy: 0.4790\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.4484 - sparse_categorical_accuracy: 0.8045 - val_loss: 2.8248 - val_sparse_categorical_accuracy: 0.4799\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 29s 171ms/step - loss: 0.4381 - sparse_categorical_accuracy: 0.8096 - val_loss: 2.8890 - val_sparse_categorical_accuracy: 0.4820\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 29s 169ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8123 - val_loss: 3.0602 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 76/100\n",
      "169/170 [============================>.] - ETA: 0s - loss: 0.4288 - sparse_categorical_accuracy: 0.8130"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtransformer_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensorBoard\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogs/transformer/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mexp_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mloss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\keras\\engine\\training.py:1606\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1593\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1594\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1604\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[0;32m   1605\u001B[0m     )\n\u001B[1;32m-> 1606\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1607\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1608\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1609\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1610\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1611\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1617\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1619\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1620\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1621\u001B[0m }\n\u001B[0;32m   1622\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\keras\\engine\\training.py:1947\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1944\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1945\u001B[0m ):\n\u001B[0;32m   1946\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 1947\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1949\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    955\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    956\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    957\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_2.10_py_3.10\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "transformer_model.fit(train_ds,\n",
    "                      validation_data=val_ds,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=[\n",
    "                          tf.keras.callbacks.TensorBoard(\"logs/transformer/\" + exp_name),\n",
    "                          tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "                                 ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(result_path, sep=\",\")\n",
    "\n",
    "df_test_modified = df_test.drop(columns=[\n",
    "    'user_id',\n",
    "    'book_id',\n",
    "    'review_id',\n",
    "    'date_added',\n",
    "    'date_updated',\n",
    "    'read_at',\n",
    "    'started_at',\n",
    "    'n_votes',\n",
    "    'n_comments'\n",
    "], inplace=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    transformer_model\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_test_data = export_model.predict(df_test_modified)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_test_data_to_result_csv(df_test, predicted_test_data, exp_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
